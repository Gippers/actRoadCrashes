---
title: "Temporal Analysis of Road Crashes in the Australian Capital Territory"
author: "Thomas Martin"
date: "`r format(Sys.time(), '%d %B, %Y')`"
execute:
  dir: project
bibliography: actCrashes.bib
csl: csl/harvard-cite-them-right.csl
---

```{r}
# Load necessary libraries
library(tidyverse)
library(MASS) # Ordered logistic regression
library(data.table)
library(astsa)
library(TSA)
library(forecast)
library(lubridate)
library(readxl)
library(patchwork)
library(sandwich) # Account for seial autocorrelation in errors
library(gt)
library(plotly)
```

# Introduction

Every day in the Australian Capital Territory (ACT), it is estimated that there are nearly 1 million car trips [@transportcanberraACTTRANSPORTSTRATEGY2020]. Unfortunately, a small proportion of those daily car trips end in accidents. This report will apply various time series modelling approaches to model the number of daily road crashes in the ACT from the 1 January 2015 to 31 December 2019. The aim of the report is to determine the best estimation technique to produce the most accurate prediction of ACT daily car crashes. The resulting model can be applied to predict the trend in future car crashes in the ACT as well as understand patterns in the prevalence of road accidents in the ACT.
The data used for this report was collected by the AFP Crash Report Form, and collected from the ACT Open Data Portal as at 30 April 2025 [@actgovernmentACTRoadCrash2025]. All crashes in the ACT must be reported to police within 24 hours, unless attended by police [@australianfederalpoliceCRASHREPORTING2025]. It is worth noting then, that this may under report serious road accidents, which would likely be attended by police. Therefore, we are likely measuring moderate and minor road accidents. This includes all crashes by users, drivers, cyclists, pedestrians and motorcyclists on roads, paths and other road related areas involving pedestrians or cyclists. All crash incidents are aggregated by day to transform the dataset into a daily time series. Therefore, the time series measures daily road crashes in the ACT reported through the AFP crash report system, hereafter referred to as ACT road crashes. This report limited the timeline of the data from 2015 to 2019 to model the data without the presence of the COVID lockdowns skewing the result. 

```{r}
# TODO as part of the introduction, outline all the sections. This section, this section....

# Potentially also discuss the origins of this analysis.
```

# Data Characteristics


We will refer to the number of car crashes as $y_t$, where $t = 1, 2, ..., 1825, 1826$. The first day of data is 1 January 2015 and the last day is 31 December 2019.

```{r}
# Load the crash data and aggregate by day
crash <- read.csv("data/ACT_Road_Crash_Data_20250430.csv")
setDT(crash)
# Aggregate count of crashes by day, note each obsevation does have a unique crashID
crash <- crash[, .(NUM_CRASHES = .N), by = .(CRASH_DATE)] 
crash[, time := 1:.N]

crash[, DATE := as.Date(CRASH_DATE, format = "%d/%m/%Y")] # Set date
crash[, CRASH_DATE := NULL]

# Keep only dates until end of 2019
# TODO should I include covid?
crash <- crash[DATE <= as.Date("31/12/2019", format = "%d/%m/%Y")]

# TODO turn into a time series
ts.crash <- ts(crash$NUM_CRASH)

#####################
# Add in the public holiday etc. data
###########
# Create day variables
crash$day <- factor(lubridate::wday(as.Date(crash$DATE), label = T),
                       ordered = F)
crash$month <- factor(lubridate::month(as.Date(crash$DATE), label = T),
                       ordered = F)

# Load the public holiday data
public_holidays <- readxl::read_excel("data/public_school_holidays.xlsx",
                                    sheet = "public_holidays")
school_holidays <-  read_excel("data/public_school_holidays.xlsx", sheet = "school_holidays")
setDT(public_holidays)
setDT(school_holidays)
#public_holidays[, rn := NULL]
# Fix the date variables
colnames(public_holidays)[1] <- "DATE"
public_holidays[, DATE := as.Date(DATE, format = "%A %d %B %Y")][
                , ph := 1
]
colnames(school_holidays)[1] <- "DATE"
school_holidays[, DATE := as.Date(DATE, "%d/%m/%Y")]

# Merge the holiday data onto the crash dataset
crash <- merge.data.table(crash, public_holidays, by = c("DATE"), all.x = T, all.y = F)
crash <- crash[is.na(ph), ph := 0]
crash <- merge.data.table(crash, school_holidays, by = c("DATE"), all.x = T, all.y = F)
crash <- crash[is.na(school_holiday), school_holiday := 0]

# Now create holidays variable that considers normal day, school_holiday, public holiday 
# or both school and public holiday
crash[, holiday := "None"]
crash <- crash[ph == 1 & school_holiday == 1, holiday := "Public and School Holiday"]
crash <- crash[ph == 0 & school_holiday == 1, holiday := "School Holiday"]
crash <- crash[ph == 1 & school_holiday == 0, holiday := "Public Holiday"]
crash[, holiday := as.factor(holiday)]

# Slightly different different day encoding:
crash$day2 <- "Sun"
crash <- crash[day == "Mon", day2 := "Mon"][
                day %in% c("Tue", "Wed"), day2 := "Tue-Wed"][
                    day %in% c("Thu", "Fri"), day2 := "Thu-Fri"][
                        day == "Sat", day2 := "Sat"]
crash <- crash[, day2 := as.factor(day2)]

# simpler month encoding
crash$month2 <- as.character(crash$month)
crash <- crash[month %in% c("Apr", "May"), month2 := "Apr-May"][
                month %in% c("Aug", "Sep", "Oct"), month2 := "Aug-Oct"]
crash <- crash[, month2 := as.factor(month2)]
crash$month2 <- relevel(crash$month2, "Jan")

# Creating the 50/50 train test split dataset
t <- 912
t.prime <- 1825

crash.train <- crash[2:t]
crash.test <- crash[(t + 1):t.prime]
```



```{r}
#| label: fig-crash-hist
#| fig-cap: "Distribution of the number of Road Crashes in the ACT from 2015 to 2019."

# Histogram of the number of crashes
plot_ly(x = crash$NUM_CRASHES, 
        type = "histogram", 
        xbins = list(size = 1),
        marker = list(
          color = "#18BC9C",
          line = list(color = "black", width = 1)
        ),
        hoverinfo = "none",
        hovertemplate = "Crashes: %{x} | Count: %{y} <extra></extra>",
        # Update the colouring of the hover label
        hoverlabel = list(
          bgcolor = "#2C3E50",       # hover box background
          bordercolor = "black",     # border colour
          font = list(color = "white")  # text colour
        )
) %>%
layout(
  xaxis = list(title = "Number of Crashes"),
  yaxis = list(title = "Count")
)

```

Observing the histogram of ACT daily road crashes, we observe that the distribution has a longer right tail suggesting the data is slightly right skewed. This suggests that the data is likely Poisson distributed, however it is not dissimilar to a normal distribution so linear regression may still be appropriate for modelling this data.

```{r}
#| label: fig-tsplot
#| fig-cap: "Daily Number of Reported ACT Road Crashes 2015 to 2019"
# Plot the entire time series
# Create labels for the first day of jan and july

dates <- format(crash$DATE, "%d-%m") %in% c("01-01", "01-07")
date.labels <- crash$DATE[dates]
data.axis <- which(dates)

# Fit a lowess trend line
low <- lowess(crash$NUM_CRASHES)
crash$trend <- low$y

# Do a time series graph below. Note the tet is greyed for the train/test split. But was hard to find a different solution

fig <- plot_ly(
  crash,
  type = 'scatter',
  mode = 'lines',
  x = ~DATE, 
  y = ~NUM_CRASHES,
  name = "Number of Crashes",
  line = list(color = "#2C3E50"),
  hovertemplate = "<br>Crashes: %{y:.2f}<extra></extra>"
) %>%
  add_lines(
    x = ~DATE, y = ~trend, name = "LOWESS Trend",
    line = list(color = "#95A5A6", dash = "dash"), 
    hovertemplate = "<br>Trend: %{y:.2f}<extra></extra>"
  ) %>%
  add_trace(
    x = crash$DATE[1:2],          # any two points
    y = c(0, 0),                  # flat line
    type = "scatter",
    mode = "lines",
    name = "Train/Test Split",
    line = list(color = "#E74C3C", dash = "dash"),
    hoverinfo = "skip",
    visible = "legendonly"       
  ) %>%
  layout(
    hovermode = "x unified",
    showlegend = TRUE,
    # Edit legend
    legend = list(
      orientation = "h",          # horizontal
      x = 0.5,                    # centered
      xanchor = "center",
      y = 1.1                     # above plot
    ),
    xaxis = list(
      title = "",#"Date",
      showspikes = TRUE,
      spikemode = "across",
      spikesnap = "cursor",
      spikecolor = "#2C3E50", 
      hoverformat = "%Y-%m-%d"
    ),
    yaxis = list(title = "Number of Crashes"), 
    # non-hoverable train/test split line
    shapes = list(
      list(
        type = "line",
        xref = "x",
        yref = "paper",          # 0–1 = bottom–top of plotting area
        x0 = '2017-06-30',
        x1 = '2017-06-30',
        y0 = 0,
        y1 = 1,
        line = list(color = "#E74C3C", width = 2, dash = "dash")
      )
    )
  )  
fig

```

We observe several patterns from the time series graph above.  The mean of the time series depends on time, with overall a slight decrease in the second half of the time series. This creates a challenge as the model will be trained on the first half of the data set only which appears to in fact have a stationary mean. This is unavoidable though as the test data set is treated as unobserved for the purposes of the modelling. Therefore, from here on out the EDA will focus on the  $1 \ldots T$ time points as this will guide later model selection. Certain periods in the dataset have decreased variance such as January, which signals the presence of non-constant variance. There is evidence of seasonality, once again around January there is a drop in the number of road crash reports and when you look at a more mirco level there is some obvious weekly seasonality.

```{r}
# Find the value of lambda
lambda <- round(BoxCox.lambda(crash.train$NUM_CRASHES), digits = 4)
```

We will split the data into train and test such that $T = 912$ and $T' = 913$, meaning that the first day of the test dataset is 1 July 2017. First, we use a Box-Cox test to find the best value of $\lambda = `r lambda`$to stabilise the variance, this is done first as per Hyndman [@hyndmanForecastingPrinciplesPractice2021]. All following time series methods will be applied to this variance stabilize time series $z_t = y_t^{\frac{1}{2}} - 1$. This procedure stabilized the variance of $z_t$, the time series graphs showing this are in see Appendix B. They show that the transformed training data set had a stationary mean, relatively stationary variance however, seasonality is still prevalent. The ACF shows strong correlation at lag 7 and the PACF shows decaying partial correlation at lag 7 (in addition to other lags), which strongly suggests weekly seasonality. Note that yearly seasonality (364 days) was also considered as a possibility however, calendar considerations make this a tricky periodicity to difference at.

```{r}
#| label: fig-boxcox-d1
#| fig-cap: "Square Root Transformed and First Differenced Daily Number of Reported ACT Road Crashes 2015 to July 2017 (training data set)"

# TODO think about what this graph should be. SHould I show square root then first differenced? 

# Make sure crash is ordered correctly
crash <- crash[order(DATE)]
crash[, z := sqrt(NUM_CRASHES) - 1]
crash[, z_diff := z - shift(z, type = "lag")] # Just in case we need it

# Add z to crash and 
crash.train <- crash[2:t]
crash.test <- crash[(t + 1):t.prime]

# Box cox transform the data
bc.crash <- ts(sqrt(crash.train$NUM_CRASHES) - 1) # TODO check the order of this
d1.crash <- ts(diff(crash.train$NUM_CRASHES))

# Plot the entire time series
# Create labels for the first day of jan and july
#diff.dates <- crash$DATE[-1]
dates <- format(crash$DATE, "%d-%m") %in% c("01-01", "01-07")
date.labels <- crash$DATE[dates]
data.axis <- which(dates)

# Fit a lowess trend line
low <- lowess(crash.train$z_diff)
crash.train$trend <- low$y

# Do a time series graph below. Note the tet is greyed for the train/test split. But was hard to find a different solution

fig <- plot_ly(
  crash.train,
  type = 'scatter',
  mode = 'lines',
  x = ~DATE, 
  y = ~z_diff,
  name = "Number of Crashes",
  line = list(color = "#2C3E50"),
  hovertemplate = "<br>Crashes: %{y:.2f}<extra></extra>"
) %>%
  add_lines(
    x = ~DATE, y = ~trend, name = "LOWESS Trend",
    line = list(color = "#95A5A6", dash = "dash"), 
    hovertemplate = "<br>Trend: %{y:.2f}<extra></extra>"
  ) %>%
  layout(
    hovermode = "x unified",
    showlegend = TRUE,
    # Edit legend
    legend = list(
      orientation = "h",          # horizontal
      x = 0.5,                    # centered
      xanchor = "center",
      y = 1.1                     # above plot
    ),
    xaxis = list(
      title = "",#"Date",
      showspikes = TRUE,
      spikemode = "across",
      spikesnap = "cursor",
      spikecolor = "#2C3E50", 
      hoverformat = "%Y-%m-%d"
    ),
    yaxis = list(title = "Square Root and First Differenced Number of Crashes")
  )  
fig

#acf(bc.crash)
#pacf(bc.crash)
```



## Seasonal Components
My prior going into this analysis, is that road crashes will occur more frequently on days where there is the greatest volume of driving. This may run slightly contrary  to intuition which may be that long weekends have more accidents however, it is likely that there are more fatal accidents from long car drives rather than road crashes which is what we are attempting to measure. In the ACT, I hypothesize that workdays are the busiest days on the road as workers are commuting to work, businesses are receiving and sending deliveries and parents are taking their children to school. Therefore, I would expect that the ACT road crashes would vary depending on the day of the week, school holidays, public holidays, when workers tend to take leave and potentially the month of the year. I was able to use the ACT government website to get past information for public holidays and public school holidays [@Years; @governmentPublicHolidaysSchool2025].



```{r}
#| label: fig-box-seasonal
#| fig-cap: "Box Plots of Seasonal Components"
#| fig-subcap: 
#| - "ACT Car Crashes by Day of Week"
#| - "ACT Car Crashes by Month"
#| - "ACT Car Crashes by Holiday"
#| fig-nrow: 3

# Plot the day, month and public holiday data fpr transformed data with plotly
fig <- plot_ly(crash.train, y = ~NUM_CRASHES, color = ~day, type = "box") %>%
  layout(yaxis = list(title = "Number of Car Crashes"), 
          xaxis = list(title = "Day of Week")
          )
fig

fig <- plot_ly(crash.train, y = ~NUM_CRASHES, color = ~month, type = "box") %>%
  layout(yaxis = list(title = "Number of Car Crashes"), 
          xaxis = list(title = "Month of Year"))
fig

fig <- plot_ly(crash.train, y = ~NUM_CRASHES, color = ~holiday, type = "box") %>%
  layout(yaxis = list(title = "Number of Car Crashes"), 
          xaxis = list(title = "Public Holiday"), 
          legend = list(
            orientation = "h",    # horizontal legend
            x = 0.5,              # center it horizontally
            xanchor = "center",
            y = 1.1              # move below plot (negative = below)
          )
        )
fig
```

As hypothesized, there is a strong pattern in the weekday data where Saturday and Sunday have the least crashes. The month plot mostly shows a significant difference only for January and maybe a slight difference for December. Holidays plot shows strong reduction in crashes, particularly for public holidays. These factors should be considered in a time-trend model.

# Model Fitting and Interpretation

```{r}
# Fit a time model z on the transformed data
time.model.test <- lm(z ~ time + day + month + holiday, 
                  data = crash.train)



z.model <- lm(z ~ day2 + month2 + holiday, 
                  data = crash.train)

# Summary that accounts for serial autocorrelation
# pvalues using a z-test
tt.coef <- z.model$coefficients
se <- sqrt(diag(vcovHAC(z.model)))
pv.tt <- pnorm(abs(tt.coef / se), lower.tail = F) * 2
tt.table <- round(data.frame(estimate = tt.coef, 
                                se = se, p.values = pv.tt), digits = 4)

# Use anova to test if grouping is ok
an.test <- anova(z.model, time.model.test)
pv <- round(an.test$`Pr(>F)`, digits = 4)

# BoxCox.lambda(z.model$residuals + 10)

crash.train[, z.r := residuals(z.model)]

# residuals for the model z 
#tsdisplay(crash.train$z.r, ci.type = "ma")

#plot(z.model)

# TODO put a model table and residuals tbale here

# TODO put the anove test of m1 and m2 in the appensix
```

## Time Trend Model

First, we will attempt to fit a linear time trend model to the transformed training data $z_t$. Note, a Poisson model was attempted on the untransformed data as the data is Poisson distributed however, the linear model fit on the transformed data was superior. The first model fit was: $M_1:z_t=β_0  + β_1 t_i+β_{2-7} day_i+β_{8-19} month_i+β_{20-23} holiday_i+ \nu_i$. Note that I chose not to fit cyclical day of week and month factors, this is because there is enough observations (912) to fit the more descriptive factor variables and, the marginal trend wasn’t particularly cyclical. This model had some day and months with similar marginal associations and time variables were insignificant, as expected from the trend plots. Days were grouped instead as: Sun, Mon, Tue-Wed, Thu-Fri and Sat and months as: Jan, Feb, Mar, Apr-May, June, July, Aug-Oct, Nov and Dec. A new model was fit with these reduced categories and the time factor removed: $M_2:z_t=β_0+β_{1-4} day_i+β_{5-12} month_i+β_{13-15} holiday_i+ \nu_i$. An Anova test was performed to see if any explanatory power was lost. The p-value of the test was 0.9997, so we failed to reject the null and find no evidence that the additional variables in M_1 are non-zero, and choose the model $M_2$. The results of the Anova test and a full table of $M_2$ is available in @sec-ap-a. 

$$
\begin{aligned}
M_2 : z_t = 3.5402 (0.1191)-0.7205 (0.0811)Sat -1.2200 (0.0768) Sun \\ + 0.3285 (0.0692) \text{Thu-Fri} + 0.2291 (0.0732) \text{Tue-Wed} \\
+0.4536 (0.1046) \text{Apr-May} +0.3564 (0.1048) \text{Aug-Oct} \\ +0.1505 (0.1833) Dec+0.1832 (0.1215) Feb+0.4917 (0.1013) Jul \\
+0.3640 (0.1316) Jun+0.3702 (0.1218) Mar + 0.1801 (0.1259) Nov \\ - 1.9650 (0.1148) \text{Public and School Holiday} \\
-1.9895 (0.2405) \text{Public Holiday} -0.5674 (0.0821) \text{School Holiday} +  \nu_t
\end{aligned}
$${#eq-M2}

We observe that Saturday and Sunday see a large negative marginal association with road crashes, whilst Monday has a positive marginal association, whilst holding all other variable constant. The day of the week being Sunday compared to Monday, is associated on average with a $1.200$ decrease in the square root of the number of ACT Road crashes, holding all other variables constant. So it seems that there are less road crashes on the weekend (Saturday has a similar affect). The month of January stands out as having a large negative marginal association with ACT road crashes and school and public holiday have large negative marginal associations, in particular the public holidays have an association that is approximately three times larger than the school holidays. A public holiday compared to a non-public or school holiday day, is associated with on average a $1.9895$ decrease in the square root of the number of  ACT road crashes, holding all other variables constant. Note that $z_t$ is sqrt transformed when interpreting the above coefficients. An analysis of the residuals shows that the variance has stabilised, however there appears to be some serial autocorrelation of the residuals, potentially of the MA(1) order. These plots are available in the appendix. In addition, due to this dependence of errors, sandwich HAC errors were used for the standard estimates, a full regression output table is in Table C. To remove serial autocorrelation, lets use some ARMA models to model the residuals.

::: callout-note
## Time Series Display for Time Trend Model (optional)
<details>
<summary>Click to expand time series diagnostic display</summary>

```{r}
#| label: fig-tsdisp-tt
#| fig-cap: "Time series display for the residuals of the time trend model."
#| fig-subcap:
#|   - "Time series of residuals"
#|   - "Autocorrelation function"
#|   - "Partial autocorrelation function"
#| layout: [[100], [50, 50]]
#| code-fold: true
#| code-summary: "Show residual diagnostics for Time Trend Model"
#| fig-width: 12
#| fig-height: 6
#| fig-align: "center"

# Time series plots, below are setup to closely mimic output of tsdisplay but with quarto functionality
plot(crash.train$DATE, crash.train$z.r, main = "", ylab = "Residuals", xlab = "Time", type = "o", 
   pch = 20, cex = 0.5)

# ACF plot
acf(crash.train$z.r, main = "", ci.type = "ma")

# PACF plot
pacf(crash.train$z.r, main = "")

```
As above, the residuals appear to demonstrate MA(1) or AR(1) autocorrelation 

</details>
:::


### Time Trend with ARMA(0, 1) Residuals (SEACF)

The ACF and PACF plot provide weak evidence of a simple ARMA(0, 1) trend in the residuals $\nu_t$. Lets perform a SEACF plot to estimate the order of an ARMA model fitted to these time-trend residuals, with a maximum order of p = 14 and q = 20.

```{r}
#| results: 'hide' # hide console output
#| message: false # hide messages
#| warning: false # hide warnings
# SEACF for the time-trend residuals
eout <- eacf(crash.train$z.r, ar.max = 14, ma.max = 20)
eacf_mat <- eout$symbol

```

```{r}
#| label: tbl-seacf
#| tbl-cap: "SEACF table of residuals of Time Trend Model. The dark blue highlights the largest triangle of zeros, which corresponds to an MA(1) model."

gt_tbl <- eacf_mat |>
as.data.frame() |>
rownames_to_column("AR order") |>
gt()  |>
#tab_header("Extended Autocorrelation Function (EACF)") |>
# Make the whole table use 100% of the container width
tab_options(
  table.width = pct(100)
) 


n_cols <- dim(eacf_mat)[2] 
col_names <- colnames(eacf_mat)

for (i in seq_len(dim(eacf_mat)[1])) {

  # columns to highlight in this row, corresponds to MA(1)
  cols_to_hl <- col_names[(i+1):n_cols]

  # highlight in gt table
  gt_tbl <- gt_tbl |>
    tab_style(
      style = list(cell_fill(color = "#2C3E50"),
      cell_text(color = "white")),
      locations = cells_body(
        rows = i,
        columns = all_of(cols_to_hl)
      )
    )
}

# Finish off the table
gt_tbl |> cols_width(
  everything() ~ pct(100 / ncol(eacf_mat))
)

# TODO colour the triangle
```

The largest triangle of zeros supports the idea that an ARMA(0, 1) model is a good choice. Note that ARMA(1, 1) is another interesting choice, however you lose the top row of 0’s, in exchange for a diagonal of 0’s with one X. Therefore, the ARMA(0, 1) is the preferred vertex point, so lets fit this model using Maximum Likelihood estimation and without a mean because the time trend model already contains a mean.

```{r}
# Actual fitting of the MA model to the residuals
ARMA.SEACF.ML = Arima(crash.train$z.r, order=c(0, 0, 1),
                 method='ML', include.mean = F) # Don't include mean as alread in time trend model
#ARMA.SEACF.ML$code
# pvalues using a z-test
se <- sqrt(diag(ARMA.SEACF.ML$var.coef))
pv.ml <- (pnorm(abs(ARMA.SEACF.ML$coef / se), lower.tail = F)) * 2
seacf.table <- data.frame(estimate = ARMA.SEACF.ML$coef, 
                                se = se, p.values = pv.ml)


```

The formula for the ARMA(0,1) model is: $\nu_t=0.1672(0.03226) \epsilon_{t-1}+ \epsilon_t$ (table of estimates available in @tbl-tt-seacf). And then the final time trend model with ARMA(0,1) residuals is:

$$
\begin{aligned}
z_t= 3.5402 (0.1191)- 0.7205 (0.0811) Sat - 1.2200 (0.0768) Sun + 0.3285 (0.0692) \text{Thu-Fri} \\
+ 0.2291 (0.0732) \text{Tue-Wed}+0.4536 (0.1046) \text{Apr-May}+0.3564 (0.1048) \text{Aug-Oct} \\ 
+0.1505 (0.1833) \text{Dec} + 0.1832 (0.1215) \text{Feb}+0.4917 (0.1013) \text{Jul} \\
 + 0.3640 (0.1316) \text{Jun}+0.3702 (0.1218) \text{Mar}+0.1801 (0.1259) \text{Nov} \\
 -1.9650 (0.1148) \text{Public and School Holiday}-1.9895 (0.2405) \text{Public Holiday} \\
 -0.5674 (0.0821) \text{School Holiday} +  0.1672 (0.03226) \epsilon_{t-1} + \epsilon_t
\end{aligned}
$${#eq-M3}

Overall, the interpretation of this model is the same as the time-trend model but without serial autocorrelation. We estimate that the error of the time-trend model follows a moving average ARMA(0, 1) process, however this is the only additional interpretation we can make.  No linear trend with time exists in the data, and the fluctuations appear to mostly be driven by seasonal trends and public holidays.


### Time Trend with ARMA(1, 0) Residuals (AIC)

In addition to the SEACF, lets also try another order estimation technique for $\nu_t$. Particularly as the SEACF plot was not definite on the best vertex choice. Instead, we will fit all combinations of ARMA(p, q) up to order 7, and find the model with the smallest Alkaline Information Criteria (AIC). 7 is used as the maximum order as strong seasonality at this order was detected and the SEACF indicates the best choice is somewhere in this range. The table of fitted AIC is below in @tbl-tt-aic, the smallest AIC was found for the ARMA(1, 0) model with an AIC of 1734.405. This was closely followed by ARMA(0, 1) model with AIC of 1734.747. 
```{r}
#| label: tbl-tt-aic
#| tbl-cap: "Estimated AIC of Time Trend model with different ARMA models for modelling the residuals. Rows contain order of p, columns contain order of q."


# Do at least 7 given the observed weekly seasonality
if(F)
{
  # Only re run this algorithm if T, in order to save time
  max.p <- 7
  max.q <- 7
  mod_aics <- matrix(0, max.p + 1, max.q + 1)
  for(p in 0:max.p)
  {
      for(q in 0:max.q)
      {
          aic <- Arima(crash.train$z.r, order = c(p, 0, q), method = "ML", include.mean = F)$aic
          mod_aics[p + 1, q + 1] <- aic
      }
  }
  mod_aics #- min(mod_aics)
  fwrite(mod_aics, "results/tt_aic_table.csv")
  mod_aics <- as.data.frame(mod_aics)
} else
{
  # Load previously computed, as this algorithm can be a little slow
  mod_aics <- as.data.frame(fread("results/tt_aic_table.csv"))
}

# turn the matrix into a gt table
colnames(mod_aics) <- 0:7
mod_aics$rownames <- 0:7

gt(mod_aics, rowname_col = "rownames") |>
    tab_style(
    style = list(
      cell_fill(color = "#2C3E50"),
      cell_text(color = "white")
    ),
    locations = cells_body(
      rows = 2,
      columns = 1
    )
  )
```

```{r}
# Fit the ARMA(1, 0 model
ARMA.AIC.ML = Arima(crash.train$z.r, order=c(1, 0, 0),
                 method='ML', include.mean = F)
#ARMA.AIC.ML$code
# pvalues using a z-test
se.aic <- sqrt(diag(ARMA.AIC.ML$var.coef))
pv.ml.aic <- (pnorm(abs(ARMA.AIC.ML$coef / se.aic), lower.tail = F)) * 2
aic.table <- data.frame(estimate = ARMA.AIC.ML$coef, 
                                se = se.aic, p.values = pv.ml.aic)
#round(aic.table, digits = 4)

# TODO include this table somehow
```

Therefore, we fit the following AR(1) model to $\nu_t=0.1690(0.03277) \nu_{t-1}+ \epsilon_t$ (see table based output in @tbl-tt-aic), which was significant to at least the 95% confidence level (output table available in appendix). Then the final model is a time-trend model with ARMA(1, 0) residuals:

$$
\begin{aligned}
z_t= 3.5402 (0.1191)- 0.7205 (0.0811) Sat - 1.2200 (0.0768) Sun + 0.3285 (0.0692) \text{Thu-Fri} \\
+ 0.2291 (0.0732) \text{Tue-Wed}+0.4536 (0.1046) \text{Apr-May}+0.3564 (0.1048) \text{Aug-Oct} \\ 
+0.1505 (0.1833) \text{Dec} + 0.1832 (0.1215) \text{Feb}+0.4917 (0.1013) \text{Jul} \\
 + 0.3640 (0.1316) \text{Jun}+0.3702 (0.1218) \text{Mar}+0.1801 (0.1259) \text{Nov} \\
 -1.9650 (0.1148) \text{Public and School Holiday}-1.9895 (0.2405) \text{Public Holiday} \\
 -0.5674 (0.0821) \text{School Holiday} +  0.1692 (0.0328) \nu_{t-1} + \epsilon_t
\end{aligned}
$${#eq-M4}

Again, there isn’t any additional interpretation outside of the time-trend model besides saying that the structure of the error of the time-trend model follows an autoregressive AR(1) pattern.

## Seasonal ARIMA Model of $Z_t$

We appear to have quite successfully fit two time-trend models. Let’s see if a Seasonal Autoregressive Integrated Moving Average (SARIMA or Seasonal ARIMA) model can outperform these time-trend models. The SARIMA approach has the benefit of being much simpler to fit as less data preprocessing is necessary, and you only need to fit one model. An ARIMA model will not be considered, as there is clear evidence of seasonality in the dataset. Analysis procedure here based on chapter 8 of forecasting principles and practice version 1 [@hyndmanForecastingPrinciplesPractice2021]. 

```{r}
#| label: fig-tsdisp-zt
#| fig-cap: "Time series display for Square Root Transformed ACT Road Crashes ($Z_t$)."
#| fig-subcap:
#|   - "Time series of residuals"
#|   - "Autocorrelation function"
#|   - "Partial autocorrelation function"
#| layout: [[100], [50, 50]]
#| code-fold: true
#| code-summary: "Show residual diagnostics for Time Trend Model"
#| fig-width: 12
#| fig-height: 6
#| fig-align: "center"

# Time series plots, below are setup to closely mimic output of tsdisplay but with quarto functionality
plot(crash.train$DATE, crash.train$z, main = "", ylab = "Residuals", xlab = "Time", type = "o", 
   pch = 20, cex = 0.5)

# ACF plot
acf(crash.train$z, main = "", ci.type = "ma")

# PACF plot
pacf(crash.train$z, main = "")
```


```{r}
#| label: fig-tsdisp-zd
#| fig-cap: "Time series display for Weekly Differenced, Square Root Transformed ACT Road Crashes ($Z_t - Z_{t-7}$)."
#| fig-subcap:
#|   - "Time series of residuals"
#|   - "Autocorrelation function"
#|   - "Partial autocorrelation function"
#| layout: [[100], [50, 50]]
#| code-fold: true
#| code-summary: "Show residual diagnostics for Time Trend Model"
#| fig-width: 12
#| fig-height: 6
#| fig-align: "center"

# 7 differenced:
plot(crash.train$DATE[-(1:7)], diff(crash.train$z, lag = 7), main = "", ylab = "Residuals", xlab = "Time", type = "o", 
   pch = 20, cex = 0.5)

# ACF plot
acf(diff(crash.train$z, lag = 7), main = "", ci.type = "ma")

# PACF plot
pacf(diff(crash.train$z, lag = 7), main = "")
```

From the plots of $z_t$, we see that the mean appears to be stationary but there is evidence of seasonality. The ACF shows spikes at lag 6 and the PACF shows also spikes at lag 7, that decay to 0. This is evidence of weekly seasonality; therefore, we take a seasonal difference of 7 and then analyse $z_t-z_{t-7}$. This plot shows a spike in the ACF at lag 7 only and decaying spikes in the PACF at 7, this indicates that we have somewhat dealt with the seasonality by differencing. There is no evidence of a trend so $d = D = 0$. The seasonally differenced ACF plot also indicates a $MA(1)_7$ trend and the PACF has a positive spike at lag 1 and the ACF has a spike at 1 which signals an ARMA(1, 1) in the non-seasonal part of the model. Therefore we start by fitting the following model: $\text{SARIMA}(1,0,1)(0,0,1)_7$ model. Models are iteratively fit adding orders based on the ACF and PACF plots those plots show stationarity. We finally end up with a $\text{SARIMA}(2,0,1)(1,0,1)_7$ model after some other excluded intermediate steps.  The estimation is done with an CSS-ML method.

```{r}
#| code-fold: true
#| code-summary: "Show residual diagnostics for SARIMA Model Building Process"

# Build a number of Sarima models

# Try SARIMA(1, 0, 1)(0, 0, 1) and then other SARIMA's
sarima.101 <- Arima(crash.train$z, order = c(1, 0, 1), 
                seasonal = list(order = c(0, 0, 1), period = 7), method = "ML", )
sarima.101.101 <- Arima(crash.train$z, order = c(1, 0, 1), 
                seasonal = list(order = c(1, 0, 1), period = 7), method = "ML", )
sarima.201.101 <- Arima(crash.train$z, order = c(2, 0, 1), 
                seasonal = list(order = c(1, 0, 1), period = 7), method = "ML", )
sarima.final <- sarima.201.101


```

::: callout-note
## Time Series Display for SARIMA Model Building Process (optional)
<details>
<summary>Click to expand time series diagnostic display</summary>

```{r}
#| label: fig-tsdisp-s1
#| fig-cap: "Time series display for residuals of $\\text{SARIMA}(1,0,1)(0, 0, 1)_7$."
#| fig-subcap:
#|   - "Time series of residuals"
#|   - "Autocorrelation function"
#|   - "Partial autocorrelation function"
#| layout: [[100], [50, 50]]
#| code-fold: true
#| code-summary: "Show residual diagnostics for Time Trend Model"
#| fig-width: 12
#| fig-height: 6
#| fig-align: "center"

# 7 differenced:
plot(crash.train$DATE, residuals(sarima.101), main = "", ylab = "Residuals", xlab = "Time", type = "o", 
   pch = 20, cex = 0.5)

# ACF plot
acf(residuals(sarima.101), main = "", ci.type = "ma")

# PACF plot
pacf(residuals(sarima.101), main = "")
```

```{r}
#| label: fig-tsdisp-s2
#| fig-cap: "Time series display for residuals of $\\text{SARIMA}(1,0,1)(1,0,1)_7$."
#| fig-subcap:
#|   - "Time series of residuals"
#|   - "Autocorrelation function"
#|   - "Partial autocorrelation function"
#| layout: [[100], [50, 50]]
#| code-fold: true
#| code-summary: "Show residual diagnostics for Time Trend Model"
#| fig-width: 12
#| fig-height: 6
#| fig-align: "center"

# 7 differenced:
plot(crash.train$DATE, residuals(sarima.101.101), main = "", ylab = "Residuals", xlab = "Time", type = "o", 
   pch = 20, cex = 0.5)

# ACF plot
acf(residuals(sarima.101.101), main = "", ci.type = "ma")

# PACF plot
pacf(residuals(sarima.101.101), main = "")

```

```{r}
#| label: fig-tsdisp-s3
#| fig-cap: "Time series display for residuals of $\\text{SARIMA}(2,0,1)(1,0,1)_7$."
#| fig-subcap:
#|   - "Time series of residuals"
#|   - "Autocorrelation function"
#|   - "Partial autocorrelation function"
#| layout: [[100], [50, 50]]
#| code-fold: true
#| code-summary: "Show residual diagnostics for Time Trend Model"
#| fig-width: 12
#| fig-height: 6
#| fig-align: "center"

# 7 differenced:
plot(crash.train$DATE, residuals(sarima.final), main = "", ylab = "Residuals", xlab = "Time", type = "o", 
   pch = 20, cex = 0.5)

# ACF plot
acf(residuals(sarima.final), main = "", ci.type = "ma")

# PACF plot
pacf(residuals(sarima.final), main = "")

tsdisplay(residuals(sarima.final), ci.type = "ma", main = "Residuals of SARIMA(2,0,1)(1, 0,1)[7]")
```

</details>
:::


```{r}
#| label: tbl-sarima-aic
#| tbl-cap: "AIC of Various SARIMA models"

aic.sarima <- data.frame(sarima.101 = sarima.101$aic, sarima.101.101 = sarima.101.101$aic,
  sarima.201.101 = sarima.201.101$aic)
#colnames(aic.sarima) <- c("SARIMA(1,0,1)(0,0,1)[7]", "SARIMA(1,0,1)(1,0,1)[7]", "SARIMA(2,0,1)(1,0,1)[7]")

aic.sarima$row <- "AIC"

gt(aic.sarima, rowname_col = "row") |>
  tab_style(
    style = list(
      cell_fill(color = "#2C3E50"),
      cell_text(color = "white")
    ),
    locations = cells_body(
      rows = 1,
      columns = 3
    )
  ) |>
  cols_label(
    sarima.101 = md("$\\text{SARIMA}(1,0,1)(0,0,1)_7$"), 
    sarima.101.101 = md("$\\text{SARIMA}(1,0,1)(1,0,1)_7$"), 
    sarima.201.101 = md("$\\text{SARIMA}(2,0,1)(1,0,1)_7$"), 
  )
  
```

Let’s now fit and estimate this model, note we will use a mean as there is no time trend part.


```{r}
#| label: tbl-sarima-est
#| tbl-cap: "Estimates for the SARIMA(2,0,1)(1,0,1)[7] model"

# TODO up to here
# Table for the samrima
# pvalues using a z-test
se.s <- sqrt(diag(sarima.final$var.coef))
pv.s <- (pnorm(abs(sarima.final$coef / se.s), lower.tail = F)) * 2
s.table <- data.frame(estimate = sarima.final$coef, 
                                se = se.s, p.values = pv.s)
s.table <- round(s.table, digits = 4)
s.table$row <- rownames(s.table)                   
gt(s.table, rowname_col = "row")
```

$$
\begin{aligned}
z_t = 1.0719 z_{t-1}-0.1356 z_{t-2}+0.9999 z_{t-7}-1.0717 z_{t-8} \\
+0.1355z_{t-9}+3.5252+ \epsilon_t-0.8023 \epsilon_{t-1}+0.9909 \epsilon_{t-7}-0.7951 \epsilon_{t-8}
\end{aligned}
$${#eq-M5}

All coefficients are significant to at least a 95% confidence level, see appendix for full model output. Interpreting this model, we find that the current value of $z_t$ is positively correlated with the past value and has a much smaller negative correlation with lag 2. Large values of crashes from the previous week have a positive correlation with the current number of ACT road rashes, which signals strong weekly seasonality. The baseline average for $z_t$ is $3.5252$. Any past innovations to the model (i.e. $\epsilon$) at lag 1, smooth out the current forecast and an innovation from the past week increases the current estimate, but the following day this is again smoothed out by the lag 8 shock. So, these lagged innovations tend to smooth out the predictions of $z_t$.


## Seasonal Auto ARIMA Model of $z_t$

Whilst the SARIMA process above found a reasonable model, there may be a better choice using an `auto.arima` procedure. Therefore, lets run `auto.arima` on the non-stabilised $z_t$ to see how it performs. Because of apparent strong weekly seasonality, we will let the `auto.arima` find a model with weekly seasonality. The max $p$ and $q$ and order will be set to 7 and seasonality will be set to true. This selects a SARIMA model of order $(1,0,0) (2,0,0)_7$, and it is estimated as:

```{r}
#| label: tbl-auto-model
#| tbl-cap: "Estimate for Seasonal Auto ARIMA Model"

# Fit a SARIMA model
a.sarima <- auto.arima(ts(crash.train$z, frequency = 7), max.p = 7, max.q = 7, max.order = 7, trace = T, seasonal = T)

# pvalues using a z-test
se.aa <- sqrt(diag(a.sarima$var.coef))
pv.aa <- (pnorm(abs(a.sarima$coef / se.aa), lower.tail = F)) * 2
as.table <- data.frame(estimate = a.sarima$coef, 
                                se = se.aa, p.values = pv.aa)

as.table <- round(as.table, digits = 4)
as.table$row <- rownames(as.table)                   
gt(as.table, rowname_col = "row")

```

$$
z_t=0.2947z_{t-1}+0.2925z_{t-7}+0.2584z_{t-14}+3.5296+ \epsilon_t
$$ {#eq-M6}

This is an odd choice by the `auto.arima` function as the residuals of this model (available in the appendix) show evidence of serial autocorrelation. All coefficients are marginally significant to at least a 95% confidence level. This model simply says that the square root of the number of ACT road crashes has a baseline of $3.5396$ and nearly equally related to the past values at lags 1, 7 and 8. Perhaps this simpler model will result in test predictions than the more flexible previously fit SARIMA model.

::: callout-note
## Time Series Display for Seasonal Auto ARIMA Model Building Process (optional)
<details>
<summary>Click to expand time series diagnostic display</summary>

```{r}
#| code-fold: true
#| code-summary: "Show residual diagnostics for SARIMA Model Building Process"

tsdisplay(residuals(a.sarima), ci.type = "ma", main = "Residuals of SARIMA(1,0,0)(2, 0, 0)[7]")

```

</details>
:::

# Model Diagnostics

Perform residual diagnostics to determine if the model from part 3 were adequately fit. Whilst I will consider outliers, no attempt will be made to assess high influence observations as cook’s distance is not valid with dependent error structures.

## Time Trend with ARMA(0, 1) Residuals (SEACF)

```{r}
# Diagnostic plots for models

model_diagnostics <- function(model)
{
    # Given ar ARMA model produces model diagnostic plots
    # standardized resiuals, ACF and pvalues
    tsdiag(model, gof.lag = 21)
    
    # Get residuals information
    train_additional_info <- crash.train %>%
        mutate(residuals = model$residuals) %>%
        mutate(fitted_values = model$fitted)
    
    # QQplot
    ggplot(train_additional_info, aes(sample = residuals)) +
        geom_qq() +
        geom_qq_line() +
        theme_bw()
}



```

::: callout-note

## Residual Diagnostic Plots for Time Trend Model with ARMA(0, 1) (optional)
<details>
<summary>Click to expand</summary>

```{r}
#| label: fig-res-arma01
#| fig-cap: "Residual Diagnostic Plots for Time Trend Model with ARMA(0, 1)"
#| fig-ncol: 2
#| fig-subcap: 
#|   - "Residual Plots"
#|   - "QQ Plot"
# SEACF ARMA Model
model_diagnostics(ARMA.SEACF.ML)

# Get the outliers
res.stand <- rstandard(ARMA.SEACF.ML)
toutlier <- crash.train[abs(res.stand) > 3]$DATE # Time of the outlier

# analyse the outliers
#crash.train[DATE %in% toutlier]
# TODO put outliers in appendix
```

</details>
:::


Examining the model diagnostics, we find the residuals do appear scattered around 0 with somewhat consistent variance around 0, which meets the linearity of errors and homoscedasticity assumptions. There does not appear to be any omitted variable bias. Furthermore, the variance assumption is met decently until the top part of the distribution which is a little heavy tailed. Given the amount of data though we shouldn't be too concerned as the CLT will help ensure that a slight variation of this isn't too problematic. Finally, the Ljung-Box test passes as no p-values cross the 0.05 threshold, signalling that there is no evidence of dependence of observations. This model has 7 outliers with absolute standardized residual greater than 3, this is on par given the number of observations we have. The outliers tend to be either school holidays or days in the middle of the week. Overall, we cannot remove these residuals but maybe there is some difference in traffic on  certain school holidays that could be better accounted for.  Overall, there is no evidence to suggest that this model egregiously violates the model diagnostics.

## Time Trend with ARMA(1, 0) Residuals (AIC)

::: callout-note
## Residual Diagnostic Plots for Time Trend Model with ARMA(1, 0) (optional)
<details>
<summary>Click to expand</summary>

```{r}
#| label: fig-res-arma10
#| fig-cap: "Residual Diagnostic Plots for Time Trend Model with ARMA(1, 0)"
#| fig-ncol: 2
#| fig-subcap: 
#|   - "Residual Plots"
#|   - "QQ Plot"
# SEACF ARMA Model
# Time Trend ARMA model
model_diagnostics(ARMA.AIC.ML)
# Get the outliers
res.stand <- rstandard(ARMA.AIC.ML)
toutlier <- crash.train[abs(res.stand) > 3]$DATE # Time of the outlier

# analyse the outliers
#crash.train[DATE %in% toutlier]
# TODO put outliers in appendix
```

</details>
:::


The constant variance and linearity of residuals assumptions are met for this model. There does not appear to be any omitted variable bias. Similarly to the previous model, the residuals are mostly normal with a slightly heavy right tail. This makes the trend in the residuals sense given that that $z_t$ is slightly right skewed. Again the Ljung-Box test passes, so there is no evidence of serial autocorrelation of the errors of the model. There are, similarly to the past time-trend ARMA(0, 1) model 7 outliers, which occur Tuesday-Friday or on a school holiday. Therefore, the residuals of this model are stationary and overall, the assumptions of the model do not appear to be violated. 

## Seasonal ARIMA Model of $z_t$ $\text{SARIMA}(2,0,1) (1,0,1)_7$


::: callout-note
## Residual Diagnostic Plots for Seasonal ARIMA Model $\text{SARIMA}(2,0,1) (1,0,1)_7$ (optional)
<details>
<summary>Click to expand</summary>

```{r}
#| label: fig-res-sarima
#| fig-cap: "Residual Diagnostic Plots for Seasonal ARIMA Model SARIMA(2,0,1) (1,0,1)[7]"
#| fig-ncol: 2
#| fig-subcap: 
#|   - "Residual Plots"
#|   - "QQ Plot"

# Auto.arima model
model_diagnostics(sarima.final)

# Get the outliers
res.stand <- rstandard(sarima.final)
toutlier <- crash.train[abs(res.stand) > 3]$DATE # Time of the outlier

# analyse the outliers
#crash.train[DATE %in% toutlier]
# TODO put outliers in appendix
```


</details>
:::

No issue with the constant variance assumption or linearity assumption. There does not appear to be any omitted variable bias. The QQ-plot shows slightly heavy bottom tail, but overall the residuals are normal. The Box-Ljung test finds no evidence of serial dependence of errors, so there is no evidence that the dependence of errors assumption is violated. Note, whilst we cannot remove outliers there are 9 outliers with a absolute standardized residual greater than 3. All but one of these outliers occur on a public holiday, most occur during a midweek public holiday. The non-public holiday outlier occurs on Wednesday 2017-04-26, on this date there were school and public holidays on Monday and Tuesday and Wednesday would have been the first day back at school. This likely caused a higher-than-expected number of road accidents as the day following a weekend tends to have the highest accident rate. However, given that it looks like a one off, and you cannot remove time series outliers, I will not attempt to control for this point. This indicates that the SARIMA model is failing to accurately predict the surge in crashes on a public holiday, which the time-trend models are capable of predicting. This highlights one of the downsides of the SARIMA approach, we cannot account for these intermittent events. Overall, none of the model assumptions are violated other than perhaps a slight violation of omitted variable bias. Seasonal Auto ARIMA Model of $z_t$ $\text{SARIMA}(1,0,0) (2,0,0)_7$.

## Auto SARIMA model $\text{SARIMA}(1,0,0)(2,0,0)_7$

::: callout-note
## Residual Diagnostic Plots for Seasonal ARIMA Model $\text{SARIMA}(1,0,0)(2,0,0)_7$ (optional)
<details>
<summary>Click to expand</summary>

```{r}
#| label: fig-res-auto-sarima
#| fig-cap: "Residual Diagnostic Plots for Seasonal ARIMA Model SARIMA(1,0,0)(2,0,0)[7]"
#| fig-ncol: 2
#| fig-subcap: 
#|   - "Residual Plots"
#|   - "QQ Plot"
# Auto.arima sarima model
model_diagnostics(a.sarima)

# Get the outliers
res.stand <- rstandard(a.sarima)
toutlier <- crash.train[abs(res.stand) > 3]$DATE # Time of the outlier

# analyse the outliers
#crash.train[DATE %in% toutlier]
# TODO put outliers in appendix
```
</details>
:::


Again, no issues with the constant variance assumption or linearity of assumption, however the residuals do not appear to be random scatter and hint at some pattern. The residuals look very normal, some tiny amount of light tails at the bottom of the distribution but overall the residuals are sufficiently normal. However, this fails the Box-Ljung test, indicating serial autocorrelation. The ACF plot shows persistent autocorrelation with lags 5, 10, 15 and so on, which does not decay to 0. Therefore, the auto.arima function selected a model that does not adequately meet the independence of observations assumption. This is a warning that auto.arima on its own is not sufficient to fit models. In addition, there are 5 outliers (absolute standardized residual greater than 3) which include the date 2017-04-26 (discussed previously) and 4 public holidays that occur on a Friday. Again, indicating that the SARIMA model fails to adequately fit some of the public holidays. 

# Data Prediction for Training Test Split

To assess the accuracy of the fitted models, use the $MSEP^{(T')}$, which is the Mean Square Error of Prediction (MSEP) for the truncated one-step-ahead forecast for time $T+1,T+2, \ldots, T'-1, T'$. The $MSEP^{(T' )}$ is calcuated as:

$$
MSEP^{(T')}=  \frac{1}{T'} \sum_{j = 1}^{T'} (y_{T + j}  - \widehat{y_{T+j|T}})
$$

In addition to the four models fitted and diagnosed, I will also include a Naive estimate. This is just the last value from the training time series at time $T$, $y_T.$ Ideally, a good model would have a smaller prediction than this naive baseline. 

```{r}
##
# 1 step truncated predictions for the time trend + ARIMA models.
##
# Set the forecast horizon
f.h <- t.prime - t

# SEACF Prediction
crash.test$pred.seacf <- (predict(z.model, newdata = crash.test, type = "response") + forecast(ARMA.SEACF.ML, h = f.h)$mean + 1)^2
# AIC ARMA model precitions
crash.test$pred.aic <- (predict(z.model, newdata = crash.test, type = "response") + forecast(ARMA.AIC.ML, h = f.h)$mean + 1)^2

# SARIMA model on the transformed crashes
crash.test$pred.sar <- (forecast(sarima.final, h = f.h)$mean +1)^2


# Auto.arima seasonl model on the transformed crashes
crash.test$pred.asar <- (forecast(a.sarima, h = f.h)$mean +1)^2

# Test naive
crash.test$naive <- crash.train[nrow(crash.train)]$NUM_CRASHES


```


```{r}
# Calculate the MSEP
MSEP <- function(actual, pred)
{
    return(1 / length(actual) * sum((actual - pred)^2))
}
```

```{r}
#| label: tbl-pred
#| tbl-cap: "Mean Squared Error of Prediction for all models trained on 1, ..., T predicting T + 1 to T'"
#| 

# Get a number of the MSEP's
pred_cols <- c("naive", "pred.seacf", "pred.aic", "pred.sar", "pred.asar")

msep_results <- sapply(pred_cols, function(col)
  round(MSEP(crash.test$NUM_CRASHES, crash.test[[col]]), 4)
)

msep_results <- as.data.table(as.list(msep_results))

colnames(msep_results) <- c("naive", "Time-Trend ARMA(0, 1)", "Time-Trend ARMA(1, 0)", "SARIMA(2, 0, 1)(1, 0, 1)[7]", "Auto SARIMA(1, 0, 0)(2, 0, 0)[7]")

msep_results[, row :=  "MSEP^(T')"]

gt(msep_results, rowname_col = "row")

```
 
In terms of $MSEP^{(T')}$, the most accurate model is the Time-Trend ARMA(1,0) model (fit using AIC method) that marginally beats out the other Time-Trend. In truth, the accuracy between the two time trend models is nearly indistinguishable, which makes sense as the ARMA errors are only different for the first few time points then decay quickly to the mean. Notably, the Time-Trend model performs more than twice as good compared to a Naïve predictor.

```{r}
#| label: fig-pred
#| fig-cap: "Model Test Prediction vs Actual for testing dataset"

# TODO better colours
fig <- plot_ly(
  crash.test,
  type = 'scatter',
  mode = 'lines',
  x = ~DATE, 
  y = ~NUM_CRASHES,
  name = "Number of Crashes",
  line = list(color = "black"),
  hovertemplate = "<br>Crashes: %{y:.2f}<extra></extra>"
) %>%
  add_lines(
    x = ~DATE, y = ~pred.seacf, name = "Time Trend with MA(1) residuals (SEACF)",
    line = list(color = "lightblue", dash = "dash"), 
    hovertemplate = "<br>Time Trend with MA(1) residuals: %{y:.2f}<extra></extra>"
  ) %>% 
  add_lines(
    x = ~DATE, y = ~pred.aic, name = "Time Trend with AR(1) residuals (AIC)",
    line = list(color = "blue", dash = "dash"), 
    hovertemplate = "<br>Time Trend with AR(1) residuals: %{y:.2f}<extra></extra>"
  ) %>%
     add_lines(
    x = ~DATE, y = ~pred.sar, name = "SARIMA Model",
    line = list(color = "orange", dash = "dash"), 
    hovertemplate = "<br>SARIMA Model: %{y:.2f}<extra></extra>"
  ) %>%
     add_lines(
    x = ~DATE, y = ~pred.asar, name = "Auto Sarima Model",
    line = list(color = "red2", dash = "dash"), 
    hovertemplate = "<br>Auto Sarima Model: %{y:.2f}<extra></extra>"
  ) %>%
  add_lines(
    x = ~DATE, y = ~naive, name = "Naive",
    line = list(color = "green", dash = "dash"), 
    hovertemplate = "<br>Naive: %{y:.2f}<extra></extra>"
  ) %>%
  layout(
    hovermode = "x unified",
    showlegend = TRUE,
    # Edit legend
    legend = list(
      orientation = "h",          # horizontal
      x = 0.5,                    # centered
      xanchor = "center",
      y = -0.05                     # above plot
    ),
    xaxis = list(
      title = "",#"Date",
      showspikes = TRUE,
      spikemode = "across",
      spikesnap = "cursor",
      spikecolor = "#2C3E50", 
      hoverformat = "%Y-%m-%d"
    ),
    yaxis = list(title = "ACT Daily Road Crashes")
  )  
fig

```


```{r}
#| label: fig-pred-4weeks
#| fig-cap: "Model Test Prediction vs Actual for First 4 Weeks"
# Plot for the first month

# TODO colour
fig <- plot_ly(
  crash.test[1:28],
  type = 'scatter',
  mode = 'lines',
  x = ~DATE, 
  y = ~NUM_CRASHES,
  name = "Number of Crashes",
  line = list(color = "black"),
  hovertemplate = "<br>Crashes: %{y:.2f}<extra></extra>"
) %>%
  add_lines(
    x = ~DATE, y = ~pred.seacf, name = "Time Trend with MA(1) residuals (SEACF)",
    line = list(color = "lightblue", dash = "dash"), 
    hovertemplate = "<br>Time Trend with MA(1) residuals: %{y:.2f}<extra></extra>"
  ) %>% 
  add_lines(
    x = ~DATE, y = ~pred.aic, name = "Time Trend with AR(1) residuals (AIC)",
    line = list(color = "blue", dash = "dash"), 
    hovertemplate = "<br>Time Trend with AR(1) residuals: %{y:.2f}<extra></extra>"
  ) %>%
     add_lines(
    x = ~DATE, y = ~pred.sar, name = "SARIMA Model",
    line = list(color = "orange", dash = "dash"), 
    hovertemplate = "<br>SARIMA Model: %{y:.2f}<extra></extra>"
  ) %>%
     add_lines(
    x = ~DATE, y = ~pred.asar, name = "Auto Sarima Model",
    line = list(color = "red2", dash = "dash"), 
    hovertemplate = "<br>Auto Sarima Model: %{y:.2f}<extra></extra>"
  ) %>%
  add_lines(
    x = ~DATE, y = ~naive, name = "Naive",
    line = list(color = "green", dash = "dash"), 
    hovertemplate = "<br>Naive: %{y:.2f}<extra></extra>"
  ) %>%
  layout(
    hovermode = "x unified",
    showlegend = TRUE,
    # Edit legend
    legend = list(
      orientation = "h",          # horizontal
      x = 0.5,                    # centered
      xanchor = "center",
      y = -0.05                     # above plot
    ),
    xaxis = list(
      title = "",#"Date",
      showspikes = TRUE,
      spikemode = "across",
      spikesnap = "cursor",
      spikecolor = "#2C3E50", 
      hoverformat = "%Y-%m-%d"
    ),
    yaxis = list(title = "ACT Daily Road Crashes")
  )  
fig
```

The required time series graph is a little difficult to interpret given the large number of data points so, an additional graph only looking at the first 28 days was included. The graph shows that neither of the time-trend models (aka SEACF or AIC) have an indistinguishable fit. The AIC and SEACF time-trend models appear to most accurately follow the peaks and troughs of the actual trend however, the SARIMA model also appears to do a decent job. The Auto Sarima model is too smoothed and appears to underfit the peaks and troughs of the data. This is the same conclusion as the $MSEP^{(T')}$ which makes sense as the accuracy measure is the mean squared distance to the true point. $MSEP^{(T')}$ can be inaccurate however when there are lots of large outliers, so the $MSEP^{(T')}$. In our case however, we didn’t see more than 10 outliers for either trend, so it is understandable that $MSEP^{(T')}$ matches the findings of the graph.

As discussed in the model fitting section there are patterns in the data that the SARIMA models can't pick up. For example, the public holidays are more difficult for the SARIMA model to fit due to changes in calendar and annual changes in public holiday days. In addition, the seasonality being modelled as factors likely provides greater flexibility to the time-trend model, which have19 parameters compared to the largest SARIMA model which has only 9 parameters. Given the large amount of training data this flexibility has likely allowed the bias of the model to be reduced significantly. The performance of the SARIMA models however is impressive given the lack of additional information about public and school holidays. In addition,  the SARIMA model only has the weekly seasonality, it doesn't consider the monthly seasonality the time-trend models do.

Comparing the models, the auto SARIMA had the worst regression diagnostics and by far had the worst accuracy. This is likely as there was something in our model that the diagnostics is telling us it is missing. However, for the models that passed the diagnostics there is no indication which of these three models would fit better. Therefore, the diagnostics were useful in indicating that the model that failed the diagnostics was a poor predictor but, it was not useful in distinguishing the predictive ability of those that passed.



# Rolling Window Prediction

The rolling window procedure estimates the one-step-ahead forecast for each point in the test dataset using the orders and parameters selected from the test dataset. Accuracy will then be measure as 

$$
MSEP_1= \frac{1}{T'} \sum_{t = T}^{T+T'-1} (y_{t + 1}- \widehat{y_{t+1|S_t}}) 
$$ {#eq-msep-roll}

However, the coefficient estimates in the linear regression, ARMA, and SARIMA models are computed using the window of observations proceeding the observation being predicting (including test data that proceeds the time being predicted). A slight alteration was made to my window sizes as the time-trend models need approximately 365 days of data to fit the monthly seasonality. As a result, I will use floor or $0.37$, $b_{0.37} = 337$ and floor of $0.74$, $b_{0.64} = 674$. This gives us two more evenly spaced samples for comparison and enough data for the model to be fit. The Naive estimator for the rolling window predictor is previous observations, this is used for comparison purposes.

```{r}
# TODO a visualisation here of the rolling window prediction
```

```{r}
# Predict the rolling window for the time trend model
rolling_predict <- function(pdq, # The non-seasonal order
                            type, # either time trend or arima
                            b, # The window size to train the model on
                            PDQ = c(0, 0, 0) # The seasonal order
                            )
    #' @description For a given window and model parameters, predict fit and predict
    #' a windowed forcast
    #' 
    #' @return a numerical list of the T+1 .. T' forecasts based on the previous window 
{
    # Size of T primce
    tp <- t.prime - t
    fcs <- rep(0, tp)
    
    for (i in 1:tp)
    {
        # Range of the window to train on
        range <- (t + i - b - 1):(t + i - 1)
        # Train the estimates but not the order for each model
        if(type == "trend")
        {
            # Specifically train both models on the given range
            model <- lm(z ~ day2 + month + ph *school_holiday, 
                              data = crash[range])
            # Model the residuals as an ARMA process
            arma <- Arima(model$residuals, order = pdq,  method = "ML", include.mean = F)
            # For window get one forecast, then shift forward 1
            f1 <- (predict(model, newdata = crash[t+i], type = "response") + forecast(arma, h = 1)$mean + 1)^2
        } else if(type == "arima")
        {
            # Model the arima model
            arma <- Arima(crash[range]$z, order = pdq,  seasonal = list(order = PDQ, period = 7), 
                          method = "ML",  transform.pars = FALSE, 
                          include.mean = T)
            
            # get the forecast
            f1 <- (forecast(arma, h = 1)$mean + 1)^2
            
        }
    
        
        # Save the windowed forecast
        fcs[i] <- f1
    }
    
    # Finally return the windowed forceast
    return(fcs)
}

# Predict the rolling window for the arima models
```

```{r}
# Get the rolling windows
b.2 <- floor(0.74 * t) # half of the training dataset
b.1 <- floor(0.37 * t) # A quarter of the training dataset
```

 
```{r}
# Get the predictions for the different datasets

if(F)
{
  # Running this block rebuilds the rolling window prediction, which takes a few mins to build
  # SEACF Prediction
  crash.test$roll.2.seacf <- rolling_predict(c(0, 0, 1), type = "trend", b = b.2)
  crash.test$roll.1.seacf <- rolling_predict(c(0, 0, 1), type = "trend", b = b.1)

  # AIC ARMA model predictions
  crash.test$roll.2.aic <- rolling_predict(c(1, 0, 0), type = "trend", b = b.2)
  crash.test$roll.1.aic <- rolling_predict(c(1, 0, 0), type = "trend", b = b.1)

  # SARIMA model on the transformed crashes
  crash.test$roll.2.sar <- rolling_predict(c(2, 0, 1), PDQ = c(0, 0, 1), type = "arima", b = b.2) # note reduced P to let it converge
  crash.test$roll.1.sar <- rolling_predict(c(2, 0, 1), PDQ = c(0, 0, 1), type = "arima", b = b.1) # note reduced P to let it converge

  # Auto.arima seasonal model on the transformed crashes
  crash.test$roll.2.asar <- rolling_predict(c(1, 0, 0), PDQ = c(2, 0, 0), type = "arima", b = b.2)
  crash.test$roll.1.asar <- rolling_predict(c(1, 0, 0), PDQ = c(2, 0, 0), type = "arima", b = b.1)


  # Test naive - last value
  crash.test[, roll.naive := shift(NUM_CRASHES, n = 1, type = "lag", fill = crash.train[nrow(crash.train)]$NUM_CRASHES)]

  # Save crash.test
  fwrite(crash.test, "results/roll_predict.csv")
} else
{
  # Otherwise by default load previously computed rollowing predictions
  crash.test <- fread("results/roll_predict.csv")
}

```


```{r}
#| label: tbl-rolling
#| tbl-cap: "MSEP for the Rolling Winodw Prediction Models"

# Get the windowed forecasts:
pred_cols <- c("roll.naive", "roll.1.seacf", "roll.2.seacf", "roll.1.aic", "roll.2.aic",
             "roll.1.sar", "roll.2.sar", "roll.1.asar", "roll.2.asar")

roll_results <- sapply(pred_cols, function(col)
  round(MSEP(crash.test$NUM_CRASHES, crash.test[[col]]), 4)
)

roll_results <- as.data.table(as.list(roll_results))
roll_results[, roll.2.naive := roll.naive]
setnames(roll_results, "roll.naive", "roll.1.naive")

# Turn into two rows based on size of window
roll_results <- melt(roll_results, measure.vars = patterns("^roll"), 
  variable.name = "var")
roll_results[, c("dummy", "roll", "model") := tstrsplit(as.character(var), "\\.")]
roll_results <- dcast(roll_results, roll ~ model, value.var = "value")

setcolorder(roll_results, c(4, 6, 2, 5, 3, 1))

# Add asterix to the sarima model results
roll_results[, sar := paste0(as.character(sar), "*")]

roll_results[, roll :=  c("MSPE_1  with b_0.37=337", "MSPE_1  with b_0.64=674")]

# Combine with old data
roll_results <- rbind(msep_results, roll_results, use.names = F)

colnames(roll_results) <- c("naive", "Time-Trend ARMA(0, 1)", "Time-Trend ARMA(1, 0)", "SARIMA(2, 0, 1)(1, 0, 1)[7]*", "Auto SARIMA(1, 0, 0)(2, 0, 0)[7]", "roll")

gt(roll_results, rowname_col = "roll")

```

*&#42The only was to get the SARIMA model to execute was the change the order from SARIMA(2,0,1) (1,0,1)_7 to SARIMA(2,0,1) (0,0,1)_7 as the more complex SARIMA model has non-finite finite-difference value and would not converge to a solution regardless of method used to fit it. The simpler model was fit for comparison purposes however, in some sense the fit was also null as the model failed to converge. Both options will be discussed.*

The $MSPE_1$ table above shows that the Time-Trend models once again perform by far the best. The difference in performance between the time-trend models again is nearly negligible, which likely indicates that either choice is appropriate, and any difference is down to chance. This time, the auto SARIMA model outperformed the SARIMA model (which also failed to converge with the original order and was altered so it would). It appears that the reduction in training data made the more complex SARIMA model unable to fit and less efficient when it was. 

The larger training windows i.e. $b_{0.64}$, performs better than the smaller window across the board. This makes sense, the smaller the training window the more bias and variance in the prediction, hence the worse the prediction is. The rankings of the models do change for the windowed rolling accuracy measures. The ARMA(0, 1) time trend model is the best for the $b_{0.64}$ window but second best for the $b_{0.37}$. For $MSEP^{(T')}$, the Time-Trend ARMA(1, 0) is marginally more accurate. The reason for this change is essentially the two predictions are the same, this is because most of the variation in the model is predicted by the time-trend portion so the difference in the ARMA(1, 0) or ARMA(0, 1) portion of the model appears to be negligible. Any difference in accuracy between the time-trend models is likely down to chance. In the $MSEP^{(T')}$, the Auto SARIMA model was the worst performer, however, is the second worst by $MSPE_1$ and the SARIMA model appears to be the worst. This is because, it appears that the simpler order of the Auto SARIMA model is better when there is less data to estimate the parameters. In addition, the Auto SARIMA model only needs to predict one step ahead. The m-step truncated prediction, misspecification may add up over time, again potentially favouring a more parsimonious model.

The conclusions from the diagnostic in section 4 do not support the conclusions here. With less training data the SARIMA model failed to converge on a solution even though it passed regression diagnostic. In addition, the Auto SARIMA model performed reasonably, on par with the performance of the SARIMA model in section 5. For the SARIMA models $MSPE_1$ was better for with more parsimonious models. The time-trend models appear to have performed well again, likely because they are much more capable of capturing the true underlying data generating process. Once last interesting finding is that going from 337 window size to 674 only increase the $MSPE_1$ of Auto SARIMA by ~1.5 whilst the $MSPE_1$ of the Time-Trend models went up by nearly 4. This supports the idea that lower SARIMA models are reasonable, but the performance improvement is more marginal with more data.



# Limitations

There were several limitations to the modelling that may have improved the modelling procedure. For the time trend model,  School holidays don’t include private school holidays in the ACT which may underestimate lower traffic flows. In addition, no data is available to understand the holiday making trends of people without kids, which may also affect traffic flow. Potentially, a VARIMA model that had as a predictor the daily traffic flow in Canberra could better capture the variation in persons travelling. In addition, some outliers were observed for higher crashes on the day following a public holiday. This is likely because this becomes the new “Monday” of the week. Further factors could be added into the model to control for this. Furthermore, the Time trend model assumes that the seasonal parameters have a constant association over time, other methods weight the factors such that more recent observed affects have greater weight, which could better reflect changed in effects over time. None of the models account for events such as Summernats or music festivals which could further improve forecast accuracy.
The forecast errors were not considered in this analysis. Further analysis should look at the forecast errors and asses a metric like the Pinball Loss to assess the accuracy of the prediction intervals. The SARIMA models only had a weekly difference, but there was some evidence as well of monthly seasonality. A better method would consider this for the SARIMA models; however, calendar differences make yearly or monthly differencing tricky with daily data. The SARIMA models saw large outliers on public holidays, including factor variables in the SARIMA model to adjust for this could lead to large improvements in the accuracy of the SARIMA models. Finally, a key limitation of this model is that we assume that the AFP reported crashes are an accurate reflection of the number of crashes in the ACT. The observed trends for example could be a related to people propensity to report rather than an actual trend in the data.

```{r}
# TODO did a consider all of the below?

#- School holidays don't account for private school differences or 
#- Noted monday and tuesday public holiday resulted in large outlier, try and control for this
#- Time trend model assumes that the seasonal affects are constant over time - ideally we would use the recent differences 
#- Non-linear trends
#- Forecast errors
#- data required for holidays etc.
#- can't do double seasons
#- Another one that is in the text somewhere
```



```{r}
# TODO future section: Look into how covid affected road accidents, using an ITR type design.
```

# Conclusion

This report fit four time series model to the ACT crash data from 1 January 2015 to 31 December 2019. The best model was found to be a Time-Trend model that fit either ARMA(1, 0) or ARMA(0, 1) errors. Whilst simpler to fit, the SARIMA models were found to less accurate and, in some cases, unable to be fit. Some trends that were discovered in the data is that the most car accidents occur on Mondays. Public Holidays, School Holidays and December sees a marked decrease in the frequency of ACT road crashes.

# Bibliography {-}

::: {#refs}
:::

# Appendix

## Appendix A: Model Outputs {#sec-ap-a}

```{r}
#| label: tbl-anove
#| tbl-cap: "Anova test of M₁ and M₂"

modelsummary::datasummary_df(as.data.frame(an.test))
```


```{r}
#| label: tbl-timetrend
#| tbl-cap: "Base Time Trend Model Estimates"
tt.table$row <- rownames(tt.table)
# Format a little
tt.table$row <- gsub("day2", "Day: ", tt.table$row)
tt.table$row <- gsub("holiday", "Holiday: ", tt.table$row)
tt.table$row <- gsub("month2", "Month: ", tt.table$row)

gt(tt.table, rowname_col = "row")
```


```{r}
#| label: tbl-tt-seacf
#| tbl-cap: "MA(1) residual estimates for time trend model. MA(1) residual estimation selected using the SEACF approach."

seacf.table <- round(seacf.table, digits = 4)

gt(seacf.table)

```


```{r}
#| label: tbl-est-aic
#| tbl-cap: "AR(1) residual estimates for time trend model. AR(1) residual estimation selected using the AIC approach."

aic.table <- round(aic.table, digits = 4)

gt(aic.table)
```